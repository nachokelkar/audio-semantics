{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d64b0416-4648-429c-b4db-599e242a0ebc",
   "metadata": {},
   "source": [
    "# Step 3\n",
    "\n",
    "Converting sequences of words into their phoneme counterparts, and also including some noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7878ab50-8ccc-4cee-9944-4298d6586294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52e2c607-de48-4085-9cd1-f1f96253384c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = os.getcwd() + \"/data/gutenberg_noisy_phonemes.txt\"\n",
    "version = \"3.2_8m\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041c1ccb-d8ee-4800-9cfe-44be39f94471",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 1 - SentencePiece embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50ffa9f1-c9d5-442b-8b74-8b88cc2231e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0075437f-f1ec-427e-a4d5-542263e1d02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentence_length = 6000\n",
    "vocab_size = 19099\n",
    "model_type = \"unigram\"\n",
    "SP_MODEL_NAME = f\"models/{model_type}_{vocab_size}_v{version}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36140c1-c17f-40d6-83d8-7149f4afd432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train sentencepiece model from `botchan.txt` and makes `m.model` and `m.vocab`\n",
    "# `m.vocab` is just a reference. not used in the segmentation.\n",
    "spm.SentencePieceTrainer.train(\n",
    "    f\"--input={input_file} \" \\\n",
    "    f\"--model_type={model_type} \" \\\n",
    "    f\"--model_prefix={SP_MODEL_NAME} \" \\\n",
    "    f\"--vocab_size={vocab_size} \" \\\n",
    "    f\"--max_sentence_length={max_sentence_length} \" \\\n",
    "    f\"--train_extremely_large_corpus\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d682060b-b195-4adb-867b-7ee826493882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁', 'ap', 'ple']\n",
      "[177, 338, 99, 567, 1652]\n",
      "[177, 338, 99]\n",
      "[177, 1232]\n"
     ]
    }
   ],
   "source": [
    "# makes segmenter instance and loads the model file (m.model)\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(f\"{SP_MODEL_NAME}.model\")\n",
    "\n",
    "# encode: text => id\n",
    "print(sp.EncodeAsPieces('apple'))\n",
    "print(sp.encode_as_ids('boyhood'))\n",
    "print(sp.encode_as_ids('boy'))\n",
    "print(sp.encode_as_ids('man'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bebfd3-a719-4ca1-ba3b-584fe0a22537",
   "metadata": {},
   "source": [
    "## Step 2 - Word2Vec encodings\n",
    "\n",
    "We use the SentencePiece encoder on our phoneme dataset to create a new dataset with it's tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24b51dd4-b188-4482-b7f4-319e277804cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Replace with entire dataset, if possible\n",
    "with open(input_file) as corpus_file:\n",
    "    corpus = corpus_file.readlines()\n",
    "\n",
    "sentences = [sp.EncodeAsPieces(sentence) for sentence in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "592e2cde-5671-434b-addd-c48713965d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lʌń', 'he', 'e', 'ńgʌl', 'ʃɐ', 'fɜ', 'tik', 'sɛt', 'ɛn', 'kod']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_from = 130\n",
    "\n",
    "sentences[0][select_from:select_from + 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba10b7d-db05-43ac-bcd8-e58a6302204a",
   "metadata": {},
   "source": [
    "Now, training Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c4867f4-8e11-42a5-acaf-132f62b71329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c348c1f-d001-4600-a5b3-38ca25877e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "W2V_MODEL_PATH = f\"models/w2v_100_v{version}.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52b092da-95af-4c7f-b9de-7aee601e93a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences, window=5, min_count=0, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a38bcb22-2192-4ca3-b00c-9b8f18697a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(W2V_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0acfbed-7fbe-405f-a13d-895b4a51546d",
   "metadata": {},
   "source": [
    "## Step 3 - Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97c990dd-bef9-4adb-88c1-db15a5aa4244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from g2p_en import G2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d6f5e1c-eecf-43d3-8ded-427ff7255102",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(W2V_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f55d9494-2342-436a-ae2d-d0ac51f34be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "g2p = G2p()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c79b7a07-a245-4db8-972a-4b6aaaaac3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_phonemes(word):\n",
    "    parsed_text = \"\".join(g2p(word))\n",
    "    final_text = \"\"\n",
    "\n",
    "    for char in parsed_text:\n",
    "        if char.isalpha():\n",
    "            final_text += char.lower()\n",
    "\n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2807f57a-5e02-40f1-881f-c87fd1473ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar_pwords(test_word):\n",
    "    parsed_text = \"\".join(g2p(test_word))\n",
    "    final_text = \"\"\n",
    "\n",
    "    for char in parsed_text:\n",
    "        if char.isalpha():\n",
    "            final_text += char.lower()\n",
    "\n",
    "    return model.wv.most_similar(final_text, topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b853104-b2d8-4f41-89c2-33d2612cce73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hyómʌn', 0.9748860001564026),\n",
       " ('dɨvæn', 0.7308272123336792),\n",
       " ('ɖivæn', 0.7231025695800781),\n",
       " ('divæn', 0.6888520121574402),\n",
       " ('ɖɨvæn', 0.6820935010910034),\n",
       " ('ɐvmän', 0.6775056719779968),\n",
       " ('ʌvmän', 0.6167342662811279),\n",
       " ('sośɐl', 0.611885130405426),\n",
       " ('mɔrʌl', 0.6032884120941162),\n",
       " ('äbsʌlót', 0.5927882194519043)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"hyómɐn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee732d7d-4722-4e6e-a90b-f35095cdf4ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dhahhhyuwmahn', 0.752903401851654),\n",
       " ('spihrihchahwahl', 0.7227702140808105),\n",
       " ('ihksternahl', 0.7202848196029663),\n",
       " ('kaorperiyl', 0.7090017795562744),\n",
       " ('raeshahnahl', 0.6954680681228638)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_pwords(\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1cdcda82-46ab-46ed-b69c-25a45ceec0c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fruwts', 0.7007562518119812),\n",
       " ('dhahfruwt', 0.6919422149658203),\n",
       " ('vehjhtahbahlz', 0.6699405908584595),\n",
       " ('fuwd', 0.6603603363037109),\n",
       " ('brehd', 0.6302711963653564)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_pwords(\"fruit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f590583-8585-475a-8fce-823fb84f1b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kwiyn', 0.6846692562103271),\n",
       " ('daoter', 0.6765732765197754),\n",
       " ('prihnsehs', 0.6557174921035767),\n",
       " ('kawntahs', 0.6210659742355347),\n",
       " ('sihster', 0.6079518795013428)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=[\"kihng\", \"wuhmahn\"], negative=[\"maen\"], topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8774b90-c60a-4135-9637-5271a0510f86",
   "metadata": {},
   "source": [
    "## Step 4 - Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2656ce7c-0437-4adc-b41c-9c03f6235e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f27e0fc9-3d83-4abd-a7db-a98c0ce6a672",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsim_scores = []\n",
    "\n",
    "with open(\"data/wordsim353_sim_rel/wordsim_similarity_goldstandard.txt\") as wordsim_fp:\n",
    "    for line in wordsim_fp.readlines():\n",
    "        scores = line.split(\"\\t\")\n",
    "        w1, w2 = scores[0], scores[1]\n",
    "        gold_score = float(scores[2])\n",
    "        wordsim_scores.append([w1, w2, gold_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a9ec0229-b664-4462-afb9-ddc274b342c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5078932269309655 , tested 121/203 pairs\n"
     ]
    }
   ],
   "source": [
    "gold = []\n",
    "preds = []\n",
    "tested = 0\n",
    "\n",
    "for pairs in wordsim_scores:\n",
    "    w1, w2 = convert_to_phonemes(pairs[0]), convert_to_phonemes(pairs[1])\n",
    "    \n",
    "    try:\n",
    "        pred = model.wv.similarity(w1, w2)\n",
    "        preds.append(pred)\n",
    "        gold.append(pairs[2])\n",
    "        tested += 1\n",
    "    \n",
    "    except KeyError:\n",
    "        continue\n",
    "\n",
    "print(spearmanr(preds, gold)[0], f\", tested {tested}/{len(wordsim_scores)} pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d0417f71-3b2f-4f5a-ba8a-005b49f9a70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.86804855485916"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word1 = \"king\"\n",
    "word2 = \"cabbage\"\n",
    "\n",
    "parsed_text1 = \"\".join(g2p(word1))\n",
    "final_text1 = \"\"\n",
    "parsed_text2 = \"\".join(g2p(word2))\n",
    "final_text2 = \"\"\n",
    "\n",
    "for char in parsed_text1:\n",
    "    if char.isalpha():\n",
    "        final_text1 += char.lower()\n",
    "\n",
    "for char in parsed_text2:\n",
    "    if char.isalpha():\n",
    "        final_text2 += char.lower()\n",
    "\n",
    "model.wv.wmdistance(sp.EncodeAsPieces(final_text1)[1:], sp.EncodeAsPieces(final_text2)[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "11f9b10f-6f7b-4a77-91e5-f6d03c9c742e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['kihng'], ['kaeb', 'ahjh'])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.EncodeAsPieces(final_text1)[1:], sp.EncodeAsPieces(final_text2)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fe2aa3fb-8aa1-4007-ac68-ca386d0d6c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40965265"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"fihz\", \"kehm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e48bfa50-c8f1-466f-b2c3-703e1146f8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c4911ed3-20ce-421a-8fe1-c6c1dcef6130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice([\"a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7bf6e9-f960-4320-a3d8-1a9ba88c39dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
