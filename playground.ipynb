{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HuBERT test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, HubertModel\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/hubert-large-ls960-ft were not used when initializing HubertModel: ['lm_head.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing HubertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing HubertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name = \"facebook/hubert-large-ls960-ft\"\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "model = HubertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d8ac12448e41bfa3a10855a228628d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/2800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset audiofolder (C:/Users/mj115gl/.cache/huggingface/datasets/audiofolder/dev-clean-6671ed00cafc447b/0.0.0/6cbdd16f8688354c63b4e2a36e1585d05de285023ee6443ffd71c4182055c0fc)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a50d5cef5be4f65b32a942213430618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = load_dataset(\"C:\\\\Users\\\\mj115gl\\\\work_dir\\\\thesis\\\\audio-semantics\\\\data\\\\LibriSpeech\\\\dev-clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the ``sampling_rate`` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BaseModelOutput' object has no attribute 'logits'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m input_values \u001b[39m=\u001b[39m processor(ds[\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m2\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39maudio\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m], return_tensors\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39minput_values  \u001b[39m# Batch size 1\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m logits \u001b[39m=\u001b[39m model(input_values)\u001b[39m.\u001b[39;49mlogits\n\u001b[0;32m      3\u001b[0m predicted_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(logits, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m transcription \u001b[39m=\u001b[39m processor\u001b[39m.\u001b[39mdecode(predicted_ids[\u001b[39m0\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BaseModelOutput' object has no attribute 'logits'"
     ]
    }
   ],
   "source": [
    "input_values = processor(ds[\"train\"][2][\"audio\"][\"array\"], return_tensors=\"pt\").input_values  # Batch size 1\n",
    "logits = model(input_values).logits\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = processor.decode(predicted_ids[0])\n",
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77040,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"][1][\"audio\"][\"array\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 199760])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 624, 32])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HubertModel(\n",
       "  (feature_extractor): HubertFeatureEncoder(\n",
       "    (conv_layers): ModuleList(\n",
       "      (0): HubertLayerNormConvLayer(\n",
       "        (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n",
       "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (1-4): 4 x HubertLayerNormConvLayer(\n",
       "        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (5-6): 2 x HubertLayerNormConvLayer(\n",
       "        (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
       "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (feature_projection): HubertFeatureProjection(\n",
       "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (projection): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): HubertEncoderStableLayerNorm(\n",
       "    (pos_conv_embed): HubertPositionalConvEmbedding(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "      (padding): HubertSamePadLayer()\n",
       "      (activation): GELUActivation()\n",
       "    )\n",
       "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x HubertEncoderLayerStableLayerNorm(\n",
       "        (attention): HubertAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): HubertFeedForward(\n",
       "          (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "          (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(input_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 624, 1024])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.last_hidden_state.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec, LineSentence\n",
    "# from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_fp = open(\"data/gtbrg_i.txt\", \"r\", encoding=\"utf-16\")\n",
    "sentences = LineSentence(line_fp)\n",
    "# line_fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'project gutenbergs the house on the borderland by william hope hodgson this ebook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_fp.seek(0)\n",
    "line_fp.readline()\n",
    "# line_fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = 100\n",
    "window = 5\n",
    "w2v_model_tag = \"TEST\"\n",
    "W2V_MODEL_PATH = f\"models/w2v_vs{vector_size}_w{window}_{w2v_model_tag}.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(\n",
    "    sentences,\n",
    "    window=window,\n",
    "    vector_size=vector_size,\n",
    "    min_count=0,\n",
    "    workers=4,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save(W2V_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'and',\n",
       " 'of',\n",
       " 'to',\n",
       " 'a',\n",
       " 'in',\n",
       " 'i',\n",
       " 'that',\n",
       " 'he',\n",
       " 'was',\n",
       " 'it',\n",
       " 'his',\n",
       " 'with',\n",
       " 'you',\n",
       " 'as']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(w2v_model.wv.key_to_index.keys())[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.8657098412513733),\n",
       " ('gentleman', 0.8089630603790283),\n",
       " ('fellow', 0.7922055125236511),\n",
       " ('person', 0.7875133752822876),\n",
       " ('creature', 0.7498121857643127),\n",
       " ('soldier', 0.7496156692504883),\n",
       " ('scotchman', 0.7041886448860168),\n",
       " ('girl', 0.6975987553596497),\n",
       " ('nobleman', 0.6809559464454651),\n",
       " ('chap', 0.6759620308876038)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(\"man\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.9092535972595215),\n",
       " ('princess', 0.8003181219100952),\n",
       " ('prince', 0.7828630805015564),\n",
       " ('sultan', 0.7463798522949219),\n",
       " ('empress', 0.7256040573120117),\n",
       " ('isabella', 0.7094663977622986),\n",
       " ('dowager', 0.6953573226928711),\n",
       " ('emperor', 0.6942340135574341),\n",
       " ('dauphin', 0.6938880085945129),\n",
       " ('duchess', 0.6818597316741943)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsim_scores = []\n",
    "\n",
    "with open(\"data/wordsim353_sim_rel/wordsim_similarity_goldstandard.txt\") as wordsim_fp:\n",
    "    for line in wordsim_fp.readlines():\n",
    "        scores = line.split(\"\\t\")\n",
    "        w1, w2 = scores[0], scores[1]\n",
    "        gold_score = float(scores[2])\n",
    "        wordsim_scores.append([w1, w2, gold_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.621953172787471 , tested 200/203 pairs\n",
      "0.6182286374851715 , including OOV\n"
     ]
    }
   ],
   "source": [
    "gold_vocab = []\n",
    "gold_all = []\n",
    "preds_vocab = []\n",
    "preds_all = []\n",
    "tested = 0\n",
    "oov = 0\n",
    "\n",
    "for pairs in wordsim_scores:\n",
    "    w1, w2 = pairs[0].lower(), pairs[1].lower()\n",
    "    \n",
    "    try:\n",
    "        pred = w2v_model.wv.similarity(w1, w2)\n",
    "        preds_vocab.append(pred)\n",
    "        gold_vocab.append(pairs[2])\n",
    "        tested += 1\n",
    "    \n",
    "    except KeyError:\n",
    "        # if w1 not in w2v_model.wv.vocab.keys():\n",
    "        #     w1_units = sp.EncodeAsPieces(w1)[1:]\n",
    "        #     w1_vectors = np.array([w2v_model.wv[unit] for unit in w1_units])\n",
    "        #     w1_vector = w1_vectors.mean(axis=0)\n",
    "        # else:\n",
    "        #     w1_vector = w2v_model.wv[w1]\n",
    "        # if w2 not in w2v_model.wv.vocab.keys():\n",
    "        #     w2_units = sp.EncodeAsPieces(w2)[1:]\n",
    "        #     w2_vectors = np.array([w2v_model.wv[unit] for unit in w2_units])\n",
    "        #     w2_vector = w2_vectors.mean(axis=0)\n",
    "        # else:\n",
    "        #     w2_vector = w2v_model.wv[w2]\n",
    "\n",
    "        # pred = cosine_similarity(w1_vector.reshape(1, -1), w2_vector.reshape(1, -1))\n",
    "        oov += 1\n",
    "    \n",
    "    preds_all.append(pred)\n",
    "    gold_all.append(pairs[2])\n",
    "        \n",
    "\n",
    "print(spearmanr(preds_vocab, gold_vocab)[0], f\", tested {tested}/{len(wordsim_scores)} pairs\")\n",
    "print(spearmanr(preds_all, gold_all)[0], f\", including OOV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "simlex_scores = []\n",
    "\n",
    "with open(\"data/SimLex-999/SimLex-999.txt\") as simlex_fp:\n",
    "    for line in simlex_fp.readlines()[1:]:\n",
    "        scores = line.split(\"\\t\")\n",
    "        w1, w2 = scores[0], scores[1]\n",
    "        gold_score = float(scores[3])\n",
    "        simlex_scores.append([w1, w2, gold_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.339987359598551 , tested 994/999 pairs\n",
      "0.3385031092150666 , including OOV\n"
     ]
    }
   ],
   "source": [
    "gold_vocab = []\n",
    "gold_all = []\n",
    "preds_vocab = []\n",
    "preds_all = []\n",
    "tested = 0\n",
    "oov = 0\n",
    "\n",
    "for pairs in simlex_scores:\n",
    "    w1, w2 = pairs[0].lower(), pairs[1].lower()\n",
    "    \n",
    "    try:\n",
    "        pred = w2v_model.wv.similarity(w1, w2)\n",
    "        preds_vocab.append(pred)\n",
    "        gold_vocab.append(pairs[2])\n",
    "        tested += 1\n",
    "    \n",
    "    except KeyError:\n",
    "        # if w1 not in w2v_model.wv.vocab.keys():\n",
    "        #     w1_units = sp.EncodeAsPieces(w1)[1:]\n",
    "        #     w1_vectors = np.array([w2v_model.wv[unit] for unit in w1_units])\n",
    "        #     w1_vector = w1_vectors.mean(axis=0)\n",
    "        # else:\n",
    "        #     w1_vector = w2v_model.wv[w1]\n",
    "        # if w2 not in w2v_model.wv.vocab.keys():\n",
    "        #     w2_units = sp.EncodeAsPieces(w2)[1:]\n",
    "        #     w2_vectors = np.array([w2v_model.wv[unit] for unit in w2_units])\n",
    "        #     w2_vector = w2_vectors.mean(axis=0)\n",
    "        # else:\n",
    "        #     w2_vector = w2v_model.wv[w2]\n",
    "\n",
    "        # pred = cosine_similarity(w1_vector.reshape(1, -1), w2_vector.reshape(1, -1))\n",
    "        oov += 1\n",
    "    \n",
    "    preds_all.append(pred)\n",
    "    gold_all.append(pairs[2])\n",
    "        \n",
    "\n",
    "print(spearmanr(preds_vocab, gold_vocab)[0], f\", tested {tested}/{len(simlex_scores)} pairs\")\n",
    "print(spearmanr(preds_all, gold_all)[0], f\", including OOV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05325e31680d4f9aac652dd1fb33d09f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39m# Add all similar words\u001b[39;00m\n\u001b[0;32m     27\u001b[0m tqdm_iterator\u001b[39m.\u001b[39mset_postfix({\u001b[39m\"\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m\"\u001b[39m : \u001b[39m\"\u001b[39m\u001b[39madding all words\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[1;32m---> 28\u001b[0m \u001b[39mfor\u001b[39;00m similar_word, score \u001b[39min\u001b[39;00m w2v_model\u001b[39m.\u001b[39;49mwv\u001b[39m.\u001b[39;49mmost_similar(word, topn\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m):\n\u001b[0;32m     29\u001b[0m     tqdm_iterator\u001b[39m.\u001b[39mset_postfix({\u001b[39m\"\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m\"\u001b[39m : \u001b[39m\"\u001b[39m\u001b[39mchecked 50 words\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[0;32m     30\u001b[0m     \u001b[39mif\u001b[39;00m score \u001b[39m>\u001b[39m threshold:\n",
      "File \u001b[1;32mc:\\Users\\mj115gl\\work_dir\\thesis\\audio-semantics\\venv\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:849\u001b[0m, in \u001b[0;36mKeyedVectors.most_similar\u001b[1;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[0;32m    846\u001b[0m \u001b[39mif\u001b[39;00m indexer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(topn, \u001b[39mint\u001b[39m):\n\u001b[0;32m    847\u001b[0m     \u001b[39mreturn\u001b[39;00m indexer\u001b[39m.\u001b[39mmost_similar(mean, topn)\n\u001b[1;32m--> 849\u001b[0m dists \u001b[39m=\u001b[39m dot(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvectors[clip_start:clip_end], mean) \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorms[clip_start:clip_end]\n\u001b[0;32m    850\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m topn:\n\u001b[0;32m    851\u001b[0m     \u001b[39mreturn\u001b[39;00m dists\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_clusters = []\n",
    "words = list(w2v_model.wv.key_to_index.keys())\n",
    "\n",
    "tqdm_iterator = tqdm(range(0, 99, 1))\n",
    "\n",
    "for threshold in tqdm_iterator:\n",
    "    threshold = threshold / 100\n",
    "    word_to_cluster = dict()  # Stores map from word to cluster\n",
    "    cluster_to_words = dict()  # Stores map from cluster to words\n",
    "    cluster_idx = 0  # Counter\n",
    "\n",
    "    for word in words:\n",
    "        tqdm_iterator.set_postfix({\"Word\": word})\n",
    "        # Check if word has already been clustered\n",
    "        if word not in word_to_cluster.keys():\n",
    "            # Create new cluster\n",
    "            cluster_idx += 1\n",
    "            # cluster_key = chr(0x0020 + cluster_idx)\n",
    "            cluster_key = cluster_idx\n",
    "\n",
    "            # Add new word to cluster\n",
    "            tqdm_iterator.set_postfix({\"status\" : \"adding new word to cluster\"})\n",
    "            cluster_to_words[cluster_key] = [word]\n",
    "            word_to_cluster[word] = cluster_key\n",
    "            \n",
    "            # Add all similar words\n",
    "            tqdm_iterator.set_postfix({\"status\" : \"adding all words\"})\n",
    "            for similar_word, score in w2v_model.wv.most_similar(word, topn=50):\n",
    "                tqdm_iterator.set_postfix({\"status\" : \"checked 50 words\"})\n",
    "                if score > threshold:\n",
    "                    cluster_to_words[cluster_key].append(similar_word)\n",
    "                    word_to_cluster[similar_word] = cluster_key\n",
    "    \n",
    "    n_clusters.append(len(cluster_to_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "681566"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = {\n",
    "    i: key for i, key in enumerate(ascii_letters)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_key = {}\n",
    "key_to_word = {}\n",
    "\n",
    "with open(\"data/quantized/dev-gold.csv\", \"r\") as key_file:\n",
    "    for line in key_file.readlines()[1:]:\n",
    "        dataset, key, _, word = line.strip().split(\",\")\n",
    "        if word not in word_to_key:\n",
    "            word_to_key[word] = {\n",
    "                'librispeech': [],\n",
    "                'synthetic': []\n",
    "            }\n",
    "        word_to_key[word][dataset].append(key)\n",
    "        key_to_word[key] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterances = {}\n",
    "\n",
    "for dataset in [\"librispeech\", \"synthetic\"]:\n",
    "    with open(f\"data/quantized/semantic/dev/{dataset}/quantized_outputs.txt\", \"r\") as utterance_file:\n",
    "        for line in utterance_file.readlines():\n",
    "            key, seq = line.strip().split(\"\\t\")\n",
    "            utterance = seq.split(\",\")[1:]\n",
    "\n",
    "            key = \"ls_\" + key_to_word[key] if dataset == \"librispeech\" else \"sy_\" + key_to_word[key]\n",
    "            if key not in utterances:\n",
    "                utterances[key] = []\n",
    "\n",
    "            utterances[key].append(\n",
    "                \"\".join(\n",
    "                    [letters[int(v)] for i, v in enumerate(utterance)]\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/level_wise/level0/utterances_original.txt\", \"w+\", encoding=\"utf-8\") as ufp:\n",
    "    for word in utterances:\n",
    "        for utterance in utterances[word]:\n",
    "            ufp.write(word + \"\\t\" + utterance + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_pairs = []\n",
    "rel_pairs = []\n",
    "\n",
    "with open(\"data/quantized/dev-pairs.csv\", \"r\") as pairs_file:\n",
    "    for line in pairs_file.readlines()[1:]:\n",
    "        dataset, _, w1, w2, sim, rel = line.strip().split(\",\")\n",
    "        if sim:\n",
    "            sim_pairs.append((dataset, w1, w2, float(sim)))\n",
    "        if rel:\n",
    "            rel_pairs.append((dataset, w1, w2, float(rel)))\n",
    "\n",
    "with open(\"data/level_wise/level0/pairs.txt\", \"w+\", encoding=\"utf-8\") as pairs_fp:\n",
    "    for pair in sim_pairs:\n",
    "        dataset, w1, w2, score = pair\n",
    "        pairs_fp.write(\n",
    "            (\"ls_\" + w1 if dataset == \"librispeech\" else \"sy_\" + w1) + \",\" +\n",
    "            (\"ls_\" + w2 if dataset == \"librispeech\" else \"sy_\" + w2) + \",\" +\n",
    "            str(score) + \",\" + \"\\n\"\n",
    "        )\n",
    "    for pair in rel_pairs:\n",
    "        dataset, w1, w2, score = pair\n",
    "        pairs_fp.write(\n",
    "            (\"ls_\" + w1 if dataset == \"librispeech\" else \"sy_\" + w1) + \",\" +\n",
    "            (\"ls_\" + w2 if dataset == \"librispeech\" else \"sy_\" + w2) + \",\" +\n",
    "            \",\" + str(score) + \"\\n\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_model = spm.SentencePieceProcessor()\n",
    "\n",
    "sp_model.Load(\"models/original_60k_250x1/level1/unigram_vs60000_lw.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_corpus = []\n",
    "\n",
    "with open(\"data/level_wise/level0/corpus_original.txt\", \"r\", encoding=\"utf-8\") as ocfp:\n",
    "    for line in ocfp.readlines():\n",
    "        original_corpus.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/original_60k_250x1/level1/corpus_ft.txt\", \"w+\", encoding=\"utf-8\") as ncfp:\n",
    "    for line in original_corpus:\n",
    "        pieces = list(\n",
    "            filter(\n",
    "                lambda x: x != \"▁\",\n",
    "                sp_model.EncodeAsPieces(line)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        units = [piece.replace(\"▁\", \"\") for piece in pieces]\n",
    "        \n",
    "        ncfp.write(\" \".join(units) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = fasttext.train_unsupervised(\n",
    "    \"data/original_60k_250x1/level1/corpus_ft.txt\",\n",
    "    \"cbow\",\n",
    "    dim=250,\n",
    "    thread=4,\n",
    "    epoch=7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fasttext.FastText._FastText"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model.save_model(\"models/fasttext_cbow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft_model = fasttext.load_model(\"models/fasttext_cbow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from levelwise_model.test_bench import LSTestBench\n",
    "from levelwise_model.utterances import WordToUtteranceMapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterance_mapping = WordToUtteranceMapping(map_file=\"data/level_wise/level0/utterances_original.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bench = LSTestBench(scores_file=\"data/level_wise/level0/pairs.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bench.ft_score_and_save(ft_model=ft_model, utterances=utterance_mapping, results_file=\"results/ft_cbow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
