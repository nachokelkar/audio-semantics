{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2c355c92-8b8c-4161-b033-3becc7bdd33a",
      "metadata": {},
      "source": [
        "# Thesis - Step 1\n",
        "\n",
        "Using pure text data to get best similarity scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "57f10954-bf97-4afc-afc5-ec3ab2f55994",
      "metadata": {
        "gather": {
          "logged": 1680194273976
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad2c9adf-f4ec-4b4a-873b-2c226205bd77",
      "metadata": {},
      "source": [
        "## Approach 1 - SentencePiece\n",
        "\n",
        "This approach uses SentencePiece on text data with only the letters to try and find words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e7d6f33c-b3ad-4f9e-8a71-d131915b1b64",
      "metadata": {
        "gather": {
          "logged": 1680194274974
        }
      },
      "outputs": [],
      "source": [
        "from gensim.models.fasttext import FastText\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "import sentencepiece as spm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3ec298bb-7639-4c4d-983b-75ed45c38643",
      "metadata": {
        "gather": {
          "logged": 1680031548880
        }
      },
      "outputs": [],
      "source": [
        "input_file = os.getcwd() + \"/data/gutenberg_no_spaces.txt\"\n",
        "max_sentence_length = 800000\n",
        "vocab_size = 2000\n",
        "model_type = \"unigram\"\n",
        "SP_MODEL_NAME = f\"./models/{model_type}_{vocab_size}_v2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "dd64cda8-e4db-4816-934a-3bd87dcf0f5e",
      "metadata": {
        "gather": {
          "logged": 1680031587088
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/Users/pranavkelkar/Work/audio-semantics/data/gutenberg_no_spaces.txt --model_type=unigram --model_prefix=./models/unigram_2000_v2 --vocab_size=2000 --max_sentence_length=800000 --train_extremely_large_corpus\n",
            "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: /Users/pranavkelkar/Work/audio-semantics/data/gutenberg_no_spaces.txt\n",
            "  input_format: \n",
            "  model_prefix: ./models/unigram_2000_v2\n",
            "  model_type: UNIGRAM\n",
            "  vocab_size: 2000\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 0.9995\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 800000\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 1\n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 0\n",
            "  bos_id: 1\n",
            "  eos_id: 2\n",
            "  pad_id: -1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "  enable_differential_privacy: 0\n",
            "  differential_privacy_noise_level: 0\n",
            "  differential_privacy_clipping_threshold: 0\n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(350) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(181) LOG(INFO) Loading corpus: /Users/pranavkelkar/Work/audio-semantics/data/gutenberg_no_spaces.txt\n",
            "trainer_interface.cc(377) LOG(WARNING) Found too long line (570514563 > 800000).\n",
            "trainer_interface.cc(379) LOG(WARNING) Too long lines are skipped in the training.\n",
            "trainer_interface.cc(380) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
            "trainer_interface.cc(406) LOG(INFO) Loaded all 0 sentences\n",
            "trainer_interface.cc(413) LOG(INFO) Skipped 1 too long sentences.\n",
            "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(422) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(427) LOG(INFO) Normalizing sentences...\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Internal: /private/var/folders/cl/bzdggp5s6pg8nkc2mqprzygc0000gn/T/pip-install-ligh4usx/sentencepiece_4b890a0199234697a57d80c0574772d4/sentencepiece/src/trainer_interface.cc(428) [!sentences_.empty()] ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# train sentencepiece model from `botchan.txt` and makes `m.model` and `m.vocab`\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# `m.vocab` is just a reference. not used in the segmentation.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m spm\u001b[39m.\u001b[39;49mSentencePieceTrainer\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m      4\u001b[0m     \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m--input=\u001b[39;49m\u001b[39m{\u001b[39;49;00minput_file\u001b[39m}\u001b[39;49;00m\u001b[39m \u001b[39;49m\u001b[39m\"\u001b[39;49m \\\n\u001b[1;32m      5\u001b[0m     \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m--model_type=\u001b[39;49m\u001b[39m{\u001b[39;49;00mmodel_type\u001b[39m}\u001b[39;49;00m\u001b[39m \u001b[39;49m\u001b[39m\"\u001b[39;49m \\\n\u001b[1;32m      6\u001b[0m     \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m--model_prefix=\u001b[39;49m\u001b[39m{\u001b[39;49;00mSP_MODEL_NAME\u001b[39m}\u001b[39;49;00m\u001b[39m \u001b[39;49m\u001b[39m\"\u001b[39;49m \\\n\u001b[1;32m      7\u001b[0m     \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m--vocab_size=\u001b[39;49m\u001b[39m{\u001b[39;49;00mvocab_size\u001b[39m}\u001b[39;49;00m\u001b[39m \u001b[39;49m\u001b[39m\"\u001b[39;49m \\\n\u001b[1;32m      8\u001b[0m     \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m--max_sentence_length=\u001b[39;49m\u001b[39m{\u001b[39;49;00mmax_sentence_length\u001b[39m}\u001b[39;49;00m\u001b[39m \u001b[39;49m\u001b[39m\"\u001b[39;49m \\\n\u001b[1;32m      9\u001b[0m     \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m--train_extremely_large_corpus\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m     10\u001b[0m )\n",
            "File \u001b[0;32m~/Work/audio-semantics/venv/lib/python3.11/site-packages/sentencepiece/__init__.py:989\u001b[0m, in \u001b[0;36mSentencePieceTrainer.Train\u001b[0;34m(arg, logstream, **kwargs)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    987\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mTrain\u001b[39m(arg\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, logstream\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    988\u001b[0m   \u001b[39mwith\u001b[39;00m _LogStream(ostream\u001b[39m=\u001b[39mlogstream):\n\u001b[0;32m--> 989\u001b[0m     SentencePieceTrainer\u001b[39m.\u001b[39;49m_Train(arg\u001b[39m=\u001b[39;49marg, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/Work/audio-semantics/venv/lib/python3.11/site-packages/sentencepiece/__init__.py:945\u001b[0m, in \u001b[0;36mSentencePieceTrainer._Train\u001b[0;34m(arg, **kwargs)\u001b[0m\n\u001b[1;32m    943\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Train Sentencepiece model. Accept both kwargs and legacy string arg.\"\"\"\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[39mif\u001b[39;00m arg \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mtype\u001b[39m(arg) \u001b[39mis\u001b[39;00m \u001b[39mstr\u001b[39m:\n\u001b[0;32m--> 945\u001b[0m   \u001b[39mreturn\u001b[39;00m SentencePieceTrainer\u001b[39m.\u001b[39;49m_TrainFromString(arg)\n\u001b[1;32m    947\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_encode\u001b[39m(value):\n\u001b[1;32m    948\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Encode value to CSV..\"\"\"\u001b[39;00m\n",
            "File \u001b[0;32m~/Work/audio-semantics/venv/lib/python3.11/site-packages/sentencepiece/__init__.py:923\u001b[0m, in \u001b[0;36mSentencePieceTrainer._TrainFromString\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    922\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_TrainFromString\u001b[39m(arg):\n\u001b[0;32m--> 923\u001b[0m     \u001b[39mreturn\u001b[39;00m _sentencepiece\u001b[39m.\u001b[39;49mSentencePieceTrainer__TrainFromString(arg)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Internal: /private/var/folders/cl/bzdggp5s6pg8nkc2mqprzygc0000gn/T/pip-install-ligh4usx/sentencepiece_4b890a0199234697a57d80c0574772d4/sentencepiece/src/trainer_interface.cc(428) [!sentences_.empty()] "
          ]
        }
      ],
      "source": [
        "# train sentencepiece model from `botchan.txt` and makes `m.model` and `m.vocab`\n",
        "# `m.vocab` is just a reference. not used in the segmentation.\n",
        "spm.SentencePieceTrainer.train(\n",
        "    f\"--input={input_file} \" \\\n",
        "    f\"--model_type={model_type} \" \\\n",
        "    f\"--model_prefix={SP_MODEL_NAME} \" \\\n",
        "    f\"--vocab_size={vocab_size} \" \\\n",
        "    f\"--max_sentence_length={max_sentence_length} \" \\\n",
        "    f\"--train_extremely_large_corpus\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ef756792",
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"data/gutenberg_no_spaces.txt\") as fp:\n",
        "    print(fp.readlines()[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "9d5458ab-230c-4494-b81d-1a03f0e974e1",
      "metadata": {
        "gather": {
          "logged": 1680194771086
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# SP_MODEL_NAME = \"unigram_8k_v2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "0c205055-8cb3-4391-b73d-acfaa9c1ef53",
      "metadata": {
        "gather": {
          "logged": 1680194772113
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['▁', 'apple']\n",
            "[0, 6647]\n",
            "[0, 201, 24]\n",
            "[0, 58]\n"
          ]
        }
      ],
      "source": [
        "# makes segmenter instance and loads the model file (m.model)\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load(f\"models/{SP_MODEL_NAME}.model\")\n",
        "\n",
        "# encode: text => id\n",
        "print(sp.EncodeAsPieces('apple'))\n",
        "print(sp.encode_as_ids('boyhood'))\n",
        "print(sp.encode_as_ids('boy'))\n",
        "print(sp.encode_as_ids('man'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e72c9453-50a4-4e22-8ebd-7020fefe4609",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Saving the vocabulary created by SentencePiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "9979009c-5718-4dfd-9e9b-2ccbc3bc00db",
      "metadata": {
        "gather": {
          "logged": 1680194775066
        }
      },
      "outputs": [],
      "source": [
        "vocab = {}\n",
        "with open(f\"models/{SP_MODEL_NAME}.vocab\", \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        word, freq = line.strip().split('\\t')\n",
        "        vocab[word] = np.exp(float(freq))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "10091f5e-499d-4301-a19f-3ba88bf86e86",
      "metadata": {
        "gather": {
          "logged": 1680194951102
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "with open(\"data/gutenberg_no_spaces.txt\") as corpus_file:\n",
        "    corpus = corpus_file.readlines()\n",
        "\n",
        "sentences = [[' '.join(sp.EncodeAsPieces(sentence)) for sentence in corpus]]\n",
        "# sentences = [[' '.join(sentence) for sentence in corpus]]\n",
        "# sentences = [list(sentence) for sentence in corpus]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ef3c7f6-c1cc-4467-afa9-bb3ffc922005",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Approach 1.1 - Using FastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d80c9150-90f6-47b4-90c8-81ef2a22fd92",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "6b780228-35b0-40f9-b8e7-3abc5260839f",
      "metadata": {
        "gather": {
          "logged": 1680195221234
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "model = FastText(size=300, window=3, min_count=0)\n",
        "model.build_vocab_from_freq(vocab)\n",
        "model.train(sentences, total_examples=len(sentences), epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "9c153352-9f44-4dfd-85e4-9e5eb4b433d7",
      "metadata": {
        "gather": {
          "logged": 1680195403033
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[b'_\\xdf\\xbc\\x91\\xcfMT`\\xf2#\\xa8n[\\xa4\\xbbEc|\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00\\x02\\x00\\x01\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00', b'\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00']\n",
            "Bad pipe message: %s [b'\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n']\n",
            "Bad pipe message: %s [b\"Y\\x98&\\x92\\xe8m\\xfa'\\x96\\x81@\\x88|\\xe1\\xd0\\xda<\\xd4\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00g\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#\\x00\\x00\\x00\\r\\x00 \\x00\\x1e\\x06\\x01\\x06\\x02\\x06\\x03\\x05\\x01\\x05\\x02\\x05\\x03\\x04\\x01\\x04\\x02\\x04\\x03\\x03\\x01\\x03\\x02\\x03\\x03\\x02\"]\n",
            "Bad pipe message: %s [b'']\n",
            "Bad pipe message: %s [b'\\x03']\n",
            "Bad pipe message: %s [b\"\\xdb\\xadJ[\\x98\\x1c\\xa9\\x88\\xc1\\xd2\\xa6\\xc1\\xd98Sg\\xbf\\xa8\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x00\\xa6\\x00l\\x004\\x00\\x9b\\x00F\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\"]\n",
            "Bad pipe message: %s [b'\\x06\\x00\\x17\\x00\\x03\\xc0\\x10']\n",
            "Bad pipe message: %s [b\"\\xec\\xeav\\x84U\\xec\\xf5\\x87\\xa0\\xf3\\xc3\\xa3k\\x8dB\\xcaor \\x1a\\x16\\x98\\xbcg\\xb0\\xa2mB&'8\\xb1\\xb3\"]\n",
            "Bad pipe message: %s [b'\\x18\\xce%\\x1bV}\\xa9\\x13\\x07+\\xf9\\xbd\\x8e\\x8dD\\xaf\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01\\x00+\\x00\\x03\\x02\\x03\\x04\\x00-\\x00\\x02\\x01\\x01\\x003\\x00&\\x00$\\x00\\x1d\\x00 \\xf1\\xc7\\xeb\\xd3\\xa1\\xdaz']\n",
            "Bad pipe message: %s [b\"\\x1d)\\xbe\\xd6\\xf5\\x0e\\xb5\\x87IH\\xf9\\x97\\xe7\\xa5qE\\x9b\\xac '\\xaePc\\xc4\\xcf8\\xf7\\xf6\\xdc\\x9ed\\x15r\\x87k\\x01\\xb4\\xa9\\x8b\\xb0\\xab\\x18\\x17\\x1e\\xe2\\xb4\\x9e\\x9cH\\r\\x8d\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\", b'\\x1e\\x00\\x1c\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08']\n",
            "Bad pipe message: %s [b'\\t\\x08\\n\\x08\\x0b\\x08\\x04']\n",
            "Bad pipe message: %s [b'\\x08\\x06\\x04\\x01\\x05\\x01\\x06', b'']\n",
            "Bad pipe message: %s [b'\\x03\\x02\\x03\\x04\\x00-\\x00\\x02\\x01\\x01\\x003\\x00&\\x00$\\x00\\x1d\\x00 S\\x15\\xbd\\x0f~\\xae\\xbcnm\\x19cm\\xbbP%\\xd6E\\x8e\\x82\\x06\\xed\\xc3']\n",
            "Bad pipe message: %s [b\"$A\\x0e\\xf1\\xaf\\x1e\\x97\\xd5\\x16<\\xb3\\x13\\xd8\\x1eJ\\xc2^a\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0s\\xc0w\\x00\\xc4\\x00\\xc3\\xc0#\\xc0'\\x00g\\x00@\\xc0r\\xc0v\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\\x14\\x009\\x008\\x00\\x88\\x00\\x87\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9a\\x00\\x99\\x00E\\x00D\\xc0\\x07\\xc0\\x11\\xc0\\x08\\xc0\\x12\\x00\\x16\\x00\\x13\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00\\xc0\\x00<\\x00\\xba\\x005\\x00\\x84\\x00/\\x00\\x96\\x00A\\x00\\x05\\x00\\n\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x000\\x00.\\x04\", b'\\x03\\x06', b'\\x07\\x08']\n",
            "Bad pipe message: %s [b'\\t\\x08\\n\\x08\\x0b\\x08\\x04']\n",
            "Bad pipe message: %s [b'\\x08\\x06\\x04\\x01\\x05\\x01\\x06', b'', b'\\x03\\x03']\n",
            "Bad pipe message: %s [b'']\n",
            "Bad pipe message: %s [b'', b'\\x02']\n",
            "Bad pipe message: %s [b'\\x05\\x02\\x06']\n",
            "Bad pipe message: %s [b'~\\xeaB\\x86\\xc6J\\x83\\x93\\x1d\\xfe\\xdc\\xf3C\\xa0\\xfd\\xa1\\xb1?\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0']\n",
            "Bad pipe message: %s [b'\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01\\x00\\x02\\x00\\x01\\x00\\xff\\x02\\x01']\n",
            "Bad pipe message: %s [b'_i6wn\\xef\\xd9{\\xd6\\xfe\\x86z\\x90\\xbd\\x906\\rr\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x00', b\"\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\"]\n",
            "Bad pipe message: %s [b'{A\\x95UV\\x14\\xc6\\xd9\\x9a\\xf8\\xab\\x83\\xf4z\\xe2\\xae\\xe2\\xa0 \\xec\\xb1=C\\xf2\\xf8R\\x07\\x82\\x9e\\xc4\\xef\\x96\\xd5\\xe5\\xb8/\\xb1\\x98\\x0c\\x00\\xd4\"\\x93\\xca.\\x83C\\xd4:\\x99\\x96\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0', b'.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04']\n",
            "Bad pipe message: %s [b'\\x03\\x06', b'\\x07\\x08']\n",
            "Bad pipe message: %s [b'\\t\\x08\\n\\x08\\x0b\\x08\\x04']\n",
            "Bad pipe message: %s [b'\\x08\\x06\\x04\\x01\\x05\\x01\\x06', b'']\n",
            "Bad pipe message: %s [b'\\x03\\x02\\x03\\x04\\x00-\\x00\\x02\\x01\\x01\\x003\\x00&\\x00$\\x00\\x1d\\x00 _\\x99\\xa0\\xf9~t0\\xb2c\\xb4C\\x17g\\xd5\\x10\\xde\\xe7\\xa7\\xdb?\\x04\\x06']\n",
            "Bad pipe message: %s [b'-\\xe2\\xcc\\xb5\\xec\\x8b!\\xe0\\xc7B\\xe7\\x85\\x93iX\\xd9Un \\xd89\\x8f\\xdb\\x97\\xef\\xe7k\\xf4\\x8fF\\x1f\\xe6c\\xde\\xfawE\\x93g']\n",
            "Bad pipe message: %s [b'\\xbf\\xb1\\xa2\\x0e\\x19j\\xe1\\xf3\\xa3\\xd9\\xff\\x89\\x85\\xc6w\\x87\\x94I\\x00\\x00|\\xc0,\\xc00\\x00']\n",
            "Bad pipe message: %s [b\"\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00<\\x005\\x00/\\x00\\x9a\\x00\\x99\\xc0\\x07\\xc0\\x11\\x00\\x96\\x00\\x05\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\"]\n",
            "Bad pipe message: %s [b'#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x000\\x00.\\x04\\x03\\x05\\x03\\x06\\x03']\n",
            "Bad pipe message: %s [b'\\x08\\x08\\x08\\t\\x08\\n\\x08', b'\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06']\n",
            "Bad pipe message: %s [b'', b'\\x03\\x03']\n",
            "Bad pipe message: %s [b'']\n",
            "Bad pipe message: %s [b'', b'\\x02']\n",
            "Bad pipe message: %s "
          ]
        }
      ],
      "source": [
        "model.save(\"models/fasttext_300_u8kv2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "ee528ea8-f8a7-4eaf-a9f6-73f62a77cfd9",
      "metadata": {
        "gather": {
          "logged": 1680195594057
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-0.0001073372\n",
            "0.08859801\n",
            "-0.053881098\n",
            "0.24784493\n",
            "0.04947821\n"
          ]
        }
      ],
      "source": [
        "print(model.wv.similarity(\"banana\", \"fruit\"))\n",
        "print(model.wv.similarity(\"banana\", \"apple\"))\n",
        "print(model.wv.similarity(\"banana\", \"man\"))\n",
        "print(model.wv.similarity(\"human\", \"man\"))\n",
        "print(model.wv.similarity(\"human\", \"banana\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "8068fbb5-d0f8-411e-b4ec-4ac08bcdf534",
      "metadata": {
        "gather": {
          "logged": 1680195612104
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('conscience', 0.6583830118179321),\n",
              " ('patience', 0.47274458408355713),\n",
              " ('thescienceof', 0.4711171090602875),\n",
              " ('audience', 0.47084999084472656),\n",
              " ('obedience', 0.45668476819992065),\n",
              " ('experience', 0.4282777011394501),\n",
              " ('impatience', 0.41176164150238037),\n",
              " ('scientist', 0.4040490388870239),\n",
              " ('convenience', 0.35665076971054077),\n",
              " ('lence', 0.3357565999031067)]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.wv.most_similar(\"science\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ab30628-7d4a-48ec-9e38-5027e7a06a59",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Approach 1.2 - Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "de00c3bf-0be8-4256-9ada-b25b580268e5",
      "metadata": {
        "gather": {
          "logged": 1680004547121
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "W2V_MODEL_PATH = \"models/w2v_100_v1.model\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "bdaf5159-36c3-4638-bb3e-8deb8d8ea6d4",
      "metadata": {
        "gather": {
          "logged": 1680005530991
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "model = Word2Vec(sentences, window=5, min_count=0, workers=4)\n",
        "# model.build_vocab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "cba718e9-7e56-4962-8f55-2896b45c274a",
      "metadata": {
        "gather": {
          "logged": 1680004691811
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "model.save(W2V_MODEL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "d0f2a252-1d31-477d-8f7d-85e9e582dce5",
      "metadata": {
        "gather": {
          "logged": 1680004328602
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# model = Word2Vec.load(W2V_MODEL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "e3817dab-eb26-49ed-a3e8-75ff44975f0a",
      "metadata": {
        "gather": {
          "logged": 1680012211655
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"word 'cat' not in vocabulary\"",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmost_similar\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/gensim/models/keyedvectors.py:553\u001b[0m, in \u001b[0;36mWordEmbeddingsKeyedVectors.most_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    551\u001b[0m     mean\u001b[38;5;241m.\u001b[39mappend(weight \u001b[38;5;241m*\u001b[39m word)\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 553\u001b[0m     mean\u001b[38;5;241m.\u001b[39mappend(weight \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab:\n\u001b[1;32m    555\u001b[0m         all_words\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab[word]\u001b[38;5;241m.\u001b[39mindex)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/gensim/models/keyedvectors.py:468\u001b[0m, in \u001b[0;36mWordEmbeddingsKeyedVectors.word_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 468\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mword \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not in vocabulary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m word)\n",
            "\u001b[0;31mKeyError\u001b[0m: \"word 'cat' not in vocabulary\""
          ]
        }
      ],
      "source": [
        "model.wv.most_similar(\"cat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e6de1388-6357-44fc-aae0-62695567bb70",
      "metadata": {
        "gather": {
          "logged": 1680003791787
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "with open(\"vocab.txt\", \"w+\") as fp:\n",
        "    fp.write(str(model.wv.vocab.keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30ad6866-adfc-4bef-a920-43f40bf70441",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Approach 2 - WordPiece tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc7b81a1-8d47-41ae-a07b-eab52ff02f6b",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from tokenizers.pre_tokenizers import PreTokenizer\n",
        "\n",
        "class FixedLengthPreTokenizer(PreTokenizer):\n",
        "    def __init__(self, n=3):\n",
        "        self.n = n\n",
        "        super().__init__()\n",
        "\n",
        "    def pre_tokenize(self, text):\n",
        "        return [(i, i+self.n) for i in range(0, len(text), self.n)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "696fe546-61db-4ddd-96d8-bb63c9954d5f",
      "metadata": {
        "gather": {
          "logged": 1679686719830
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from tokenizers import trainers\n",
        "from tokenizers.models import WordPiece\n",
        "from tokenizers import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(WordPiece())\n",
        "\n",
        "trainer = trainers.WordPieceTrainer(\n",
        "    vocab_size=10000, \n",
        "    special_tokens=[\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"],\n",
        "    initial_alphabet= list(\n",
        "        \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
        "    ),\n",
        "    continuing_subword_prefix=\"##\",\n",
        "    show_progress=True,\n",
        "    min_frequency=1\n",
        ")\n",
        "\n",
        "# tokenizer.pre_tokenizer = FixedLengthPreTokenizer()  # or another value for n\n",
        "\n",
        "tokenizer.train(\n",
        "    files=[\"data/gutenberg_no_spaces.txt\"], \n",
        "    trainer=trainer\n",
        ")\n",
        "\n",
        "tokenizer.save(\"models/tokenizer.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b206bacb-ebb0-46d5-a865-b1e4d8ebc799",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Approach 3 - Character CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "29babca4-750a-41b2-b69e-38535364ebc8",
      "metadata": {
        "gather": {
          "logged": 1680029630371
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b89c4832-4fc5-486d-aa02-c75f2acd20d0",
      "metadata": {
        "gather": {
          "logged": 1680029630479
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:32\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3810f35b-5b5a-4a13-9549-4dbdb4b6111b",
      "metadata": {
        "gather": {
          "logged": 1680030688818
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'à', 'á', 'â', 'ã', 'ä', 'æ', 'ç', 'è', 'é', 'ê', 'ë', 'ì', 'í', 'î', 'ï', 'ñ', 'ò', 'ó', 'ô', 'ö', 'ù', 'û', 'ü', 'ā', 'œ', 'α', 'β', 'δ', 'ε', 'η', 'θ', 'ι', 'κ', 'λ', 'μ', 'ν', 'ο', 'π', 'ρ', 'ς', 'σ', 'τ', 'υ', 'φ', 'ω']\n"
          ]
        }
      ],
      "source": [
        "# To prevent recomputing alphabet each time\n",
        "vocab_path = 'data/gutenberg_vocabulary.txt'\n",
        "\n",
        "vocabulary = sorted(set(open(vocab_path).read().split()))\n",
        "print(vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "45a9e8f0-a90f-4059-8ae2-0a7aa2fdaf9b",
      "metadata": {
        "gather": {
          "logged": 1680030689866
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "class CharDataset(Dataset):\n",
        "    def __init__(self, corpus_path, seq_length):\n",
        "        self.corpus_path = corpus_path\n",
        "        self.seq_length = seq_length\n",
        "        self.vocab = vocabulary # Load the unique characters in the corpus\n",
        "        self.char_to_index = {c: i for i, c in enumerate(self.vocab)} # Map each character to an index\n",
        "        self.index_to_char = {i: c for i, c in enumerate(self.vocab)} # Map each index to a character\n",
        "        self.corpus_size = os.path.getsize(corpus_path)\n",
        "        # self.num_chunks = int(self.corpus_size / (1024 * 1024)) # Split the corpus into 1MB chunks\n",
        "        # self.chunk_size = int(self.corpus_size / self.num_chunks)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.num_chunks\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        start_pos = idx * self.chunk_size\n",
        "        # end_pos = (idx + 1) * self.chunk_size\n",
        "        with open(self.corpus_path) as f:\n",
        "            f.seek(start_pos)\n",
        "            chunk = f.read(self.chunk_size).replace('\\n', '')\n",
        "        input_seq = chunk[:-1]\n",
        "        target = chunk[1:]\n",
        "        input_seq = [self.char_to_index[c] for c in input_seq]\n",
        "        target = [self.char_to_index[c] for c in target]\n",
        "        input_seq = torch.LongTensor(input_seq)\n",
        "        target = torch.LongTensor(target)\n",
        "        return input_seq, target\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7d2ebfd2-4549-4926-bcb8-67994ab9ebc4",
      "metadata": {
        "gather": {
          "logged": 1680029633154
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "class CharacterCNN(nn.Module):\n",
        "    def __init__(self, input_size, embedding_size, filter_sizes, num_filters):\n",
        "        super(CharacterCNN, self).__init__()\n",
        "        self.embedding_size = embedding_size\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.conv_layers = nn.ModuleList([\n",
        "            nn.Conv1d(in_channels=embedding_size, out_channels=num_filters, kernel_size=fs, padding=0)\n",
        "            for fs in filter_sizes\n",
        "        ])\n",
        "        self.fc = nn.Linear(len(filter_sizes) * num_filters, input_size)\n",
        "        \n",
        "    def forward(self, input):\n",
        "        # input shape: (seq_len, batch_size)\n",
        "        embedded = self.embedding(input) # shape: (seq_len, batch_size, embedding_size)\n",
        "        embedded = embedded.permute(1, 2, 0) # shape: (batch_size, embedding_size, seq_len)\n",
        "        conv_outputs = []\n",
        "        for conv in self.conv_layers:\n",
        "            conv_outputs.append(torch.relu(conv(embedded)))\n",
        "        pooled_outputs = [torch.max(conv_output, dim=-1)[0] for conv_output in conv_outputs]\n",
        "        fc_input = torch.cat(pooled_outputs, dim=-1)\n",
        "        output = self.fc(fc_input)\n",
        "        # print(output.shape)\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "56d18853-0fff-494d-912e-f331522f1bc1",
      "metadata": {
        "gather": {
          "logged": 1680029633849
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "corpus_path = 'data/gutenberg.txt'\n",
        "seq_length = 20\n",
        "vocab_size = len(vocabulary)\n",
        "embedding_size = 128\n",
        "# output_size = 100 # size of the word embeddings\n",
        "filter_sizes = [3, 4] # filter sizes for convolutional layers\n",
        "num_filters = 64 # number of filters for each convolutional layer\n",
        "batch_size = 4\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "650455bf-809a-493a-ad42-ced2485acef0",
      "metadata": {
        "gather": {
          "logged": 1680029634784
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Create dataset and dataloader\n",
        "dataset = CharDataset(corpus_path, seq_length)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b7574c23-ee63-4030-99aa-2b2c62d7bc97",
      "metadata": {
        "gather": {
          "logged": 1680029637461
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Create model and optimizer\n",
        "model = CharacterCNN(vocab_size, embedding_size, filter_sizes, num_filters)\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c447f1c1-ec3d-48b4-a4ce-a6759a5c7a52",
      "metadata": {
        "gather": {
          "logged": 1680029720070
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 1048739]) torch.Size([4, 1048739])\n",
            "torch.Size([4, 1048739])\n",
            "torch.Size([1048739, 71])\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Expected input batch_size (1048739) to match target batch_size (4).",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     11\u001b[0m output \u001b[38;5;241m=\u001b[39m model(input_seq)\n\u001b[0;32m---> 12\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/nn/modules/loss.py:1164\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/torch/nn/functional.py:3014\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3012\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3013\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3014\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (1048739) to match target batch_size (4)."
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for i, (input_seq, target) in enumerate(dataloader):\n",
        "        # print(sys.getsizeof(input_seq), sys.getsizeof(target), input_seq.shape)\n",
        "        print(input_seq.shape, target.shape)\n",
        "        input_seq = input_seq.to(device)\n",
        "        print(target.shape)\n",
        "        target = target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(input_seq)\n",
        "        loss = nn.CrossEntropyLoss()(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f'Epoch {epoch + 1}/{num_epochs}, Batch {i + 1}/{len(dataloader)}, Loss: {total_loss / (i + 1)}')\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss / len(dataloader)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dd755e2-773d-4165-8054-e27349f7caa7",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
